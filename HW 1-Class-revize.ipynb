{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Olu≈üturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import pylab\n",
    "from scipy.stats import shapiro\n",
    "import scipy.stats as stats \n",
    "import statsmodels.stats.api as sms\n",
    "from scipy.stats import levene\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import pearsonr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Info(): \n",
    "    def __init__(self,data):\n",
    "        data = pd.read_csv(\"bankdata.csv\")\n",
    "        print(data.head())\n",
    "        print(data.info())\n",
    "        print(data.describe().T)\n",
    "        print(data.shape)\n",
    "        print(data.columns)\n",
    "    def Num_data(self):\n",
    "        print(self.data.select_dtypes(include=['float64','int64']))\n",
    "    def Cat_data(self):\n",
    "        print(self.data.select_dtypes(include=[\"object\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualization():\n",
    "    def __init__(self,data):\n",
    "        self.data = data     \n",
    "    def barplot(self,x,y,z = None):\n",
    "        bar = sns.barplot(x = x, y = y, hue = z, data = self.data);\n",
    "        return bar   \n",
    "    def catplot(self, x, y, z = None):\n",
    "        cat = sns.catplot(x = x, y = y, hue = z, data = self.data);\n",
    "        return cat    \n",
    "    def histogram(self,x, y = None):\n",
    "        hist = sns.FacetGrid(self.data, hue = y, height = 5, xlim = (0, 10000)).map(sns.kdeplot, x, shade= True).add_legend();\n",
    "        return hist    \n",
    "    def boxplot(self,x, y = None, z = None):\n",
    "        box = sns.boxplot(x = x, y = y, hue = z, data=self.data);\n",
    "        return box    \n",
    "    def jointplot(self,x,y):\n",
    "        joint = sns.jointplot(x = x, y = y ,data = self.data, kind = \"reg\");\n",
    "        return joint    \n",
    "    def scatter(self, x, y, z = None, s = None):\n",
    "        sca = sns.scatterplot(x = x, y = y, hue=z, size = s, data = self.data);\n",
    "        return sca    \n",
    "    def lmplot(self, x, y, z = None, c = None, r = None):\n",
    "        lm = sns.lmplot(x = x, y = y, hue = z, col = c, row = r, data = self.data);\n",
    "        return lm    \n",
    "    def pairplot(self, x = None):\n",
    "        pair = sns.pairplot(self.data, kind = \"reg\", hue = x);\n",
    "        return pair    \n",
    "    def heatmap(self):\n",
    "        heat = sns.heatmap(self.data, annot = True, fmt = \"d\");\n",
    "        return heat     \n",
    "    def lineplot(self, x, y, z = None, s = None):\n",
    "        lin = sns.lineplot(x = x, y = y, hue = z, style = s, markers = True,  dashes = False, data = self.data);\n",
    "        return lin    \n",
    "    def countplot(self, column):\n",
    "        count = sns.countplot(self.data.iloc[:,column], data = self.data, palette = \"Set3\");\n",
    "        return count    \n",
    "    def cross_tab(self,x,y):\n",
    "        cross = pd.crosstab(x, y)\n",
    "        return cross    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessing:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def Delete_col(self, inplace):\n",
    "        del_col = self.data.dropna(axis=1, inplace=inplace)\n",
    "        return del_col \n",
    "    def calc_vif(self):\n",
    "        vif[\"variables\"] = self.data.columns\n",
    "        vif[\"VIF\"] = [variance_inflation_factor(self.data.values, i) for i in range(self.data.shape[1])]\n",
    "        return(vif)\n",
    "    def Dummy(self):\n",
    "        dummy_data = pd.get_dummies(self.data)\n",
    "        return dummy_data\n",
    "    def DropColumn(self, column):\n",
    "        drop =  self.data.drop(column, inplace=True, axis=1)\n",
    "        return drop\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class statistic():\n",
    "    def __init__(self, data):\n",
    "        self.data=data  \n",
    "    def shapiro(self):\n",
    "        for col in self.data.columns[1:]:\n",
    "            if self.data[col].dtypes != object :\n",
    "                stat, p = shapiro(self.data[col]) \n",
    "    def Delete_col(self, inplace):\n",
    "        del_col = self.data.dropna(axis=1, inplace=inplace)\n",
    "        return del_col\n",
    "    \n",
    "    def Delete_row(self, inplace):\n",
    "        del_row = self.data.dropna(axis=0, inplace=inplace)\n",
    "        return del_row\n",
    "    def levene(self, col_1, col_2):\n",
    "        stats.levene(self.data[col_1],self.data[col_2])\n",
    "        print('Statistics=%.3f, p=%.3f' % (stat,p))             \n",
    "    def ttest_one(self,column,popmean):\n",
    "        stat, p = self.stats.ttest_one(self.data[column], popmean = popmean)\n",
    "        print(\"Statistics:%3.3f, p=%.3f \" % (stat,p))      \n",
    "    def ttest_two(self, col_1, col_2):\n",
    "        columns = pd.concat([self.data[col_1],self.data[col_2]], axis=1)\n",
    "        stat, p=stats.ttest_ind(columns[col_1],columns[col_1], equal_var = False )\n",
    "        print(\"Statistics:%3.3f, p=%.3f \" % (stat,p))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-7d95f67a11b1>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-7d95f67a11b1>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    def __init__(self,filename):\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "class supervised(model):\n",
    "    def regression():\n",
    "            \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    \n",
    "    def fitModel(self, X, Y):\n",
    "        lm = sm.OLS(y,X)\n",
    "        model = lm.fit()\n",
    "        return model\n",
    "    \n",
    "    def fitModelwithFormula(self):\n",
    "        lm = smf.ols(data)\n",
    "        model = lm.fit()\n",
    "        return model\n",
    "    \n",
    "    def modelSummary(self, model):\n",
    "        model.summary()\n",
    "    \n",
    "    def getParams(self, model):\n",
    "        model.params\n",
    "    \n",
    "    def getFittedValues(self, x,y):\n",
    "         print(\"Model Fitted Values: \",model.fittedvalues[x:y])\n",
    "        \n",
    "    def getModelIntercept(self,model):\n",
    "        print(\"Model Intercept: \",model.intercept_)\n",
    "    \n",
    "    def getModelCoef(self,model):\n",
    "        print(\"Model Coef: \",model.coef_)\n",
    "\n",
    "    def getModelScore(self,model, x,y):\n",
    "        print(\"Model Score: \",model.score(x,y))\n",
    "    \n",
    "    def meanSquaredError(self, y, model):\n",
    "        mse= mean_squared_error(y, model.fittedvalues)\n",
    "        print(\"Mean Squared Error: \", mse)\n",
    "        \n",
    "    def modelFittedValuesMean(self, model)\n",
    "        print(\" Fitted Values Mean\", mse/model.fittedvalues.mean())\n",
    "        \n",
    "    def rmse(self, mse):\n",
    "        rmse=np.sqrt(mse)\n",
    "        print(\"rmse: \",rmse)\n",
    "        \n",
    "    class LogisticRegression():\n",
    "    \n",
    "    def __init__(self,filename):\n",
    "        data = pd.read_csv(filename)\n",
    "    \n",
    "    def fit(self, loj, X,y):\n",
    "        loj_model = loj.fit(X,y)\n",
    "        return loj_model\n",
    "    \n",
    "    def modelIntercept(loj_model):\n",
    "        print(\"Model Intercept: \", loj_model.intercept_)\n",
    "    \n",
    "    def modelCoef(loj_model):\n",
    "        print(\"Model Coef: \", loj_model.coef_)\n",
    "    \n",
    "    def getProbability(X):\n",
    "        probability = loj_model.predict(X)[0:10]\n",
    "        return probability\n",
    "    \n",
    "    def predictProba(X):\n",
    "        print(loj_model.predict_proba(X)[0:10][:,0:2])\n",
    "    \n",
    "    def rocCurveArea(X):\n",
    "        logit_roc_auc = roc_auc_score(y, loj_model.predict(X))\n",
    "        print(\"Area : \",logit_roc_auc)\n",
    "        return logit_roc_auc\n",
    "    \n",
    "    def classification():\n",
    "        \n",
    "class unsupervised(model):\n",
    "    def clustering():\n",
    "\n",
    "class GridsearchCV(): # results of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def Logisctic_Regression(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "\n",
    "        loj =LogisticRegression(solver = \"liblinear\")\n",
    "        loj_model_ = loj.fit(X_train, y_train)\n",
    "            \n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(accuracy_score(y_train, loj_model_.predict(X_train)))\n",
    "        print(accuracy_score(y_test, loj_model_.predict(X_test)))\n",
    "        print(classification_report(y_test,loj_model_.predict(X_test)))\n",
    "        print(cross_val_score(loj_model, X_test, y_test, cv =10).mean())\n",
    "\n",
    "        logit_roc_auc = roc_auc_score(y, loj_model.predict(X))\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(self.y, loj_model.predict_proba(X)[:,1])\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label='AUC (area = %0.2f)' % logit_roc_auc)\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Oranƒ±')\n",
    "        plt.ylabel('True Positive Oranƒ±')\n",
    "        plt.title('ROC')\n",
    "        plt.show()\n",
    "        \n",
    "    def Model_Tuning(self,X_train= None,y_train = None,params= None,model=None):\n",
    "        model_cv = GridSearchCV(model, params, cv=10, n_jobs = -1, verbose = 2)\n",
    "        model_tuned = model_cv.fit(X_train, y_train)\n",
    "        print(\"En iyi parametreler: \" + str(model_tuned.best_params_))\n",
    "        \n",
    "    def NN_Classification(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        mlpc = MLPClassifier(best_params).fit(X_train_scaled, y_train)\n",
    "        print(mlpc)\n",
    "        y_pred = mlpc.predict(X_test_scaled)\n",
    "        \n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "    def CART_Classification(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        cart = DecisionTreeClassifier(best_params)\n",
    "        cart_model = cart.fit(X_train, y_train)\n",
    "        print(cart_model)\n",
    "        \n",
    "        fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (50,50), dpi=300)\n",
    "\n",
    "        tree.plot_tree(cart_model,\n",
    "           filled = True);\n",
    "\n",
    "        fig.savefig('tree_class.png')\n",
    "        print(skompile(cart_model.predict).to(\"python/code\"))\n",
    "        y_pred = cart_model.predict(X_test)\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        \n",
    "        \n",
    "    def RF_Classification(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        rf_model = RandomForestClassifier(best_params).fit(X_train, y_train)\n",
    "        print(rf_model)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(confusion_matrix(y_test,y_pred))\n",
    "        \n",
    "        Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by = \"Importance\", \n",
    "                       axis = 0, \n",
    "                       ascending = True).plot(kind =\"barh\", color = \"r\")\n",
    "\n",
    "        plt.xlabel(\"Deƒüi≈üken √ñnem D√ºzeyleri\")\n",
    "        \n",
    "    def NN_Regression(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        mlp_model = MLPRegressor(best_params,hidden_layer_sizes = (100,20)).fit(X_train_scaled, y_train)\n",
    "        print(mlp_model)\n",
    "        y_pred = mlp_model.predict(X_test_scaled)\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "    def CART_Regression(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        cart_model = DecisionTreeRegressor(best_params)\n",
    "        cart_model.fit(X_train, y_train)\n",
    "        fig, axes = plt.subplots(nrows = 1,ncols = 1,figsize = (50,50), dpi=300)\n",
    "        tree.plot_tree(cart_model,\n",
    "                   filled = True);\n",
    "        fig.savefig('tree_reg.png')\n",
    "        \n",
    "        print(skompile(cart_model.predict).to('python/code'))\n",
    "        y_pred =cart_model.predict(X_test)\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        \n",
    "    def RF_Regression(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        rf_model = RandomForestRegressor(best_params)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "        Importance = pd.DataFrame({\"Importance\": rf_tuned.feature_importances_*100},\n",
    "                         index = X_train.columns)\n",
    "        Importance.sort_values(by=\"Importance\", axis=0, ascending=True).plot(kind=\"barh\", color=\"r\")\n",
    "        plt.xlabel(\"Degiskenlerin Onem Duzeyleri\")\n",
    "        plt.show()\n",
    "        \n",
    "    def SVR(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        svr = SVR(best_params).fit(X_train, y_train)\n",
    "        print(svr)\n",
    "        y_pred = svr.predict(X_test)\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        \n",
    "    def CatBoostRegressor(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        catb = CatBoostRegressor(best_params)\n",
    "        catb_model = catb.fit(X_train, y_train)\n",
    "        print(catb_model)\n",
    "        y_pred = catb_model.predict(X_test)\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "    def KNeighborsRegressor(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        knn_model = KNeighborsRegressor(best_params).fit(X_train, y_train)\n",
    "        print(knn_model)\n",
    "        print(knn_model.n_neighbors)\n",
    "        print(knn_model.effective_metric_)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "        RMSE = [] \n",
    "        RMSE_CV = []\n",
    "        for k in range(10):\n",
    "            k = k+1\n",
    "            knn_model = KNeighborsRegressor(n_neighbors = k).fit(X_train, y_train)\n",
    "            y_pred = knn_model.predict(X_train) \n",
    "            rmse = np.sqrt(mean_squared_error(y_train,y_pred)) \n",
    "            rmse_cv = np.sqrt(-1*cross_val_score(knn_model, X_train, y_train, cv=10, \n",
    "                                         scoring = \"neg_mean_squared_error\").mean())\n",
    "            RMSE.append(rmse) \n",
    "            RMSE_CV.append(rmse_cv)\n",
    "            print(\"k =\" , k , \"i√ßin RMSE deƒüeri: \", rmse, \"RMSE_CV deƒüeri: \", rmse_cv )\n",
    "    \n",
    "    def KMEANS(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "        pca = PCA(n_components=10)\n",
    "        X_reduced_train = pca.fit_transform(scale(X_train))\n",
    "        X_reduced_test = pca.fit_transform(scale(X_test))\n",
    "        pca_data = pca.fit_transform(scale(data))\n",
    "        pca_data = pd.DataFrame(pca_data)\n",
    "        print(np.cumsum(np.round(pca.explained_variance_ratio_, decimals = 4) * 100))\n",
    "        n_cluster = input(\"Please enter n_cluster: \")\n",
    "        kmeans = KMeans(n_clusters=n_cluster)\n",
    "        k_fit = kmeans.fit(data_pca)\n",
    "        print(k_fit.cluster_centers_)\n",
    "        print(k_fit.labels_)\n",
    "        visualizer = KElbowVisualizer(kmeans, k=(2,50))\n",
    "        visualizer.fit(data_pca)\n",
    "        visualizer.poof()\n",
    "        n_cluster = input(\"Please enter n_cluster: \")\n",
    "        kmeans = KMeans(n_clusters= n_cluster)\n",
    "        k_fit = kmeans.fit(data_pca)\n",
    "        kumeler = k_fit.labels_\n",
    "        merkezler = k_fit.cluster_centers_\n",
    "        plt.scatter(data_pca.iloc[:,0], data_pca.iloc[:,1], merkezler, c= kumeler,  cmap = \"viridis\")\n",
    "        plt.scatter(merkezler[:,0], merkezler[:,1], c=\"black\", s= 200, alpha = 0.5)\n",
    "        \n",
    "    def NaiveBayes(self,X_train=None,X_test=None,y_train=None,y_test=None):\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        nb = MultinomialNB()\n",
    "        nb_model = nb.fit(X_train_scaled, y_train)\n",
    "        print(nb_model)\n",
    "        y_pred = nb_model.predict(X_test_scaled)\n",
    "        print(\"Test ba≈üarƒ± oranƒ±\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        y_pred = nb_model.predict(X_train_scaled)\n",
    "        print(\"Train ba≈üarƒ± oranƒ±\")\n",
    "        print(accuracy_score(y_train, y_pred))\n",
    "        \n",
    "    def SVC(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        kernel = input(\"Please enter kernel: \")\n",
    "        svm_model = SVC(kernel = kernel).fit(X_train, y_train)\n",
    "        print(svm_model)\n",
    "        y_pred = svm_model.predict(X_test)\n",
    "        print(\"Test ba≈üarƒ± oranƒ±\")\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test,svc_model.predict(X_test)))\n",
    "        y_pred = svm_model.predict(X_train)\n",
    "        print(\"Train ba≈üarƒ± oranƒ±\")\n",
    "        print(accuracy_score(y_train, y_pred))\n",
    "        print(classification_report(y_train,svm_model.predict(X_train)))\n",
    "        \n",
    "    def KNeighborsClassifier(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        knn = KNeighborsClassifier(best_params)\n",
    "        knn_model = knn.fit(X_train, y_train)\n",
    "        print(knn_model)\n",
    "        y_pred = knn_model.predict(X_test)\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "    def CatBoostClassifier(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        cat_model = CatBoostClassifier(best_params).fit(X_train, y_train)\n",
    "        y_pred = cat_model.predict(X_test)\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "    def GradientBoostingClassifier(self,X_train=None,X_test=None,y_train=None,y_test=None,best_params=None):\n",
    "        gbm_model = GradientBoostingClassifier(best_params).fit(X_train, y_train)\n",
    "        y_pred = gbm_model.predict(X_test)\n",
    "        print(accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred))\n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
